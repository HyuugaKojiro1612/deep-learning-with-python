{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19829b38",
   "metadata": {},
   "source": [
    "# 7.3 Using built-in training and evaluation loops\n",
    "\n",
    "### *The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e520998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2952 - accuracy: 0.9128 - val_loss: 0.1714 - val_accuracy: 0.9514\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1608 - accuracy: 0.9533 - val_loss: 0.1260 - val_accuracy: 0.9640\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1305 - accuracy: 0.9631 - val_loss: 0.1068 - val_accuracy: 0.9716\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9752\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation='relu')(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation='softmax')(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "\n",
    "# Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor.\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]) \n",
    "\n",
    "# Use fit() to train the model, optionally providing validation data to monitor performance on unseen data.\n",
    "model.fit(train_images, train_labels, epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "\n",
    "# Use evaluate() to compute the loss and metrics on new data.\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Use predict() to compute classification probabilities on new data.\n",
    "predictions = model.predict(test_images) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869b207",
   "metadata": {},
   "source": [
    "There are a couple of ways you can customize this simple workflow:\n",
    "- Provide your own custom metrics.\n",
    "- Pass callbacks to the `fit()` method to schedule actions to be taken at specific\n",
    "points during training.\n",
    "\n",
    "Let’s take a look at these.\n",
    "\n",
    "## 7.3.1 Writing your own metrics\n",
    "\n",
    "Metrics are key to measuring the performance of your model—in particular, to measuring the difference between its performance on the training data and its performance on the test data. Commonly used metrics for classification and regression are\n",
    "already part of the built-in `keras.metrics` module, and most of the time that’s what\n",
    "you will use. But if you’re doing anything out of the ordinary, you will need to be able\n",
    "to write your own metrics. It’s simple!\n",
    "\n",
    " A Keras metric is a subclass of the `keras.metrics.Metric` class. Like layers, a metric has an internal state stored in TensorFlow variables. Unlike layers, these variables\n",
    "aren’t updated via backpropagation, so you have to write the state-update logic yourself, which happens in the `update_state()` method.\n",
    "\n",
    " For example, here’s a simple custom metric that measures the root mean squared\n",
    "error (RMSE).\n",
    "\n",
    "### *Implementing a custom metric by subclassing the `Metric` class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc091f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Subclass the Metric class.\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    \n",
    "    # Define the state variables in the constructor. Like for layers, you have access to the add_weight() method.\n",
    "    def __init__(self, name='rmse', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name='mse_sum', initializer='zeros')\n",
    "        self.total_samples = self.add_weight(name='total_samples', initializer='zeros', dtype='int32')\n",
    "        \n",
    "    # Implement the state update logic in update_state(). The y_true argument is the targets (or labels) for one batch, \n",
    "    # while y_pred represents the corresponding predictions from the model. You can ignore the sample_weight argument—\n",
    "    # we won’t use it here.\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # To match our MNIST model, we expect categorical predictions and integer labels.\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "        \n",
    "    # Return the current value of the metric.\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "    \n",
    "    # Expose a way to reset the metric state without having to reinstantiate it—\n",
    "    # this enables the same metric objects to be used across different\n",
    "    # epochs of training or across both training and evaluation.\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ccc68",
   "metadata": {},
   "source": [
    "Custom metrics can be used just like built-in ones. You can now see the `fit()` progress bar displaying the RMSE of your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7aac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2937 - accuracy: 0.9127 - rmse: 7.1782 - val_loss: 0.1462 - val_accuracy: 0.9570 - val_rmse: 7.3566\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1612 - accuracy: 0.9543 - rmse: 7.3517 - val_loss: 0.1288 - val_accuracy: 0.9638 - val_rmse: 7.3998\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1314 - accuracy: 0.9632 - rmse: 7.3803 - val_loss: 0.1026 - val_accuracy: 0.9725 - val_rmse: 7.4240\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9758 - rmse: 7.4376\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels, epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a73412",
   "metadata": {},
   "source": [
    "## 7.3.2 Using callbacks\n",
    "\n",
    "A callback is an object (a class instance implementing specific methods) that is passed to the model in the call to `fit()` and that is called by the model at various points during training. It has access to all the available data about the state of the model and its performance, and it can take action: interrupt training, save a model, load a different weight set, or otherwise alter the state of the model.\n",
    "\n",
    " Here are some examples of ways you can use callbacks:\n",
    "- *Model checkpointing*—Saving the current state of the model at different points during training.\n",
    "- *Early stopping*—Interrupting training when the validation loss is no longer improving (and of course, saving the best model obtained during training).\n",
    "- *Dynamically adjusting the value of certain parameters during training*—Such as the learning rate of the optimizer.\n",
    "- *Logging training and validation metrics during training, or visualizing the representations learned by the model as they’re updated*—The `fit()` progress bar that you’re familiar with is in fact a callback!\n",
    "\n",
    "The `keras.callbacks` module includes a number of built-in callbacks (this is not an\n",
    "exhaustive list):\n",
    "- `keras.callbacks.ModelCheckpoint`\n",
    "- `keras.callbacks.EarlyStopping`\n",
    "- `keras.callbacks.LearningRateScheduler`\n",
    "- `keras.callbacks.ReduceLROnPlateau`\n",
    "- `keras.callbacks.CSVLogger`\n",
    "\n",
    "Let’s review two of them to give you an idea of how to use them: `EarlyStopping` and\n",
    "`ModelCheckpoint`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93ab0b",
   "metadata": {},
   "source": [
    "### The `EarlyStopping` and `ModelCheckpoint` callbacks\n",
    "\n",
    "When you’re training a model, there are many things you can’t predict from the start.\n",
    "In particular, you can’t tell how many epochs will be needed to get to an optimal validation loss. Our examples so far have adopted the strategy of training for enough\n",
    "epochs that you begin overfitting, using the first run to figure out the proper number\n",
    "of epochs to train for, and then finally launching a new training run from scratch\n",
    "using this optimal number. Of course, this approach is wasteful. A much better way to\n",
    "handle this is to stop training when you measure that the validation loss is no longer\n",
    "improving. This can be achieved using the `EarlyStopping` callback.\n",
    "\n",
    " The `EarlyStopping` callback interrupts training once a target metric being monitored has stopped improving for a fixed number of epochs. For instance, this callback\n",
    "allows you to interrupt training as soon as you start overfitting, thus avoiding having to\n",
    "retrain your model for a smaller number of epochs. This callback is typically used in\n",
    "combination with `ModelCheckpoint`, which lets you continually save the model during\n",
    "training (and, optionally, save only the current best model so far: the version of the\n",
    "model that achieved the best performance at the end of an epoch).\n",
    "\n",
    "### *Using the `callbacks` argument in the `fit()` method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433ba251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2972 - accuracy: 0.9117 - val_loss: 0.1480 - val_accuracy: 0.9570\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1611 - accuracy: 0.9531 - val_loss: 0.1206 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1303 - accuracy: 0.9629 - val_loss: 0.1062 - val_accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1151 - accuracy: 0.9688 - val_loss: 0.1020 - val_accuracy: 0.9738\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1061 - accuracy: 0.9713 - val_loss: 0.0956 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0955 - accuracy: 0.9746 - val_loss: 0.0861 - val_accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0887 - accuracy: 0.9751 - val_loss: 0.0928 - val_accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0833 - accuracy: 0.9775 - val_loss: 0.0897 - val_accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a81724910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks are passed to the model via the callbacks argument in fit(), which takes a list of callbacks.\n",
    "# You can pass any number of callbacks.\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( # Interrupts training when improvement stops.\n",
    "        monitor=\"val_accuracy\",    # Monitors the model's validation accuracy.\n",
    "        patience=2,                # Interrupts training when accuracy has stopped improving for two epochs.\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(      # Saves the current weights after every epoch.\n",
    "        filepath=\"checkpoint_path.keras\", # Path to the destination model file.\n",
    "        monitor=\"val_loss\",               # These two arguments mean you won’t overwrite the model file unless val_loss  \n",
    "        save_best_only=True,              # has improved, which allows you to keep the best model seen during training.\n",
    "    )\n",
    "]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])       # You monitor accuracy, so it should be part of the model’s metrics.\n",
    "\n",
    "# Note that because the callback will monitor validation loss and validation accuracy, \n",
    "# you need to pass validation_data to the call to fit().\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79bd40",
   "metadata": {},
   "source": [
    "Note that you can always save models manually after training as well—just call\n",
    "`model.save('my_checkpoint_path')`. To reload the model you’ve saved, just use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('checkpoint_path.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380739e",
   "metadata": {},
   "source": [
    "## 7.3.3 Writing your own callbacks\n",
    "\n",
    "If you need to take a specific action during training that isn’t covered by one of the\n",
    "built-in callbacks, you can write your own callback. Callbacks are implemented by subclassing the `keras.callbacks.Callback` class. You can then implement any number\n",
    "of the following transparently named methods, which are called at various points\n",
    "during training:\n",
    "\n",
    "- `on_epoch_begin(epoch, logs)`—Called at the start of every epoch.\n",
    "- `on_epoch_end(epoch, logs)`—Called at the end of every epoch.\n",
    "- `on_batch_begin(batch, logs)`—Called right before processing each batch.\n",
    "- `on_batch_end(batch, logs)`—Called right after processing each batch.\n",
    "- `on_train_begin(logs)`—Called at the start of training.\n",
    "- `on_train_end(logs)`—Called at the end of training.\n",
    "\n",
    "These methods are all called with a `logs` argument, which is a dictionary containing\n",
    "information about the previous batch, epoch, or training run—training and validation metrics, and so on. The `on_epoch_*` and `on_batch_*` methods also take the\n",
    "epoch or batch index as their first argument (an integer).\n",
    "\n",
    " Here’s a simple example that saves a list of per-batch loss values during training\n",
    "and saves a graph of these values at the end of each epoch.\n",
    "\n",
    "### *Creating a custom callback by subclassing the `Callback` class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cefb402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2942 - accuracy: 0.9137 - val_loss: 0.1455 - val_accuracy: 0.9576\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1590 - accuracy: 0.9538 - val_loss: 0.1102 - val_accuracy: 0.9689\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1294 - accuracy: 0.9636 - val_loss: 0.0986 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1118 - accuracy: 0.9694 - val_loss: 0.0979 - val_accuracy: 0.9734\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1003 - accuracy: 0.9721 - val_loss: 0.0862 - val_accuracy: 0.9774\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0979 - accuracy: 0.9738 - val_loss: 0.0941 - val_accuracy: 0.9769\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0883 - accuracy: 0.9760 - val_loss: 0.0889 - val_accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0825 - accuracy: 0.9779 - val_loss: 0.0919 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0755 - accuracy: 0.9790 - val_loss: 0.0922 - val_accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0753 - accuracy: 0.9802 - val_loss: 0.0898 - val_accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a8042e650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses, \n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []\n",
    "        \n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9f809",
   "metadata": {},
   "source": [
    "## 7.3.4 Monitoring and visualization with TensorBoard\n",
    "\n",
    "To do good research or develop good models, you need rich, frequent feedback about\n",
    "what’s going on inside your models during your experiments. That’s the point of running experiments: to get information about how well a model performs—as much\n",
    "information as possible. Making progress is an iterative process, a loop—you start with\n",
    "an idea and express it as an experiment, attempting to validate or invalidate your idea.\n",
    "You run this experiment and process the information it generates. This inspires your\n",
    "next idea. The more iterations of this loop you’re able to run, the more refined and\n",
    "powerful your ideas become. Keras helps you go from idea to experiment in the least\n",
    "possible time, and fast GPUs can help you get from experiment to result as quickly as\n",
    "possible. But what about processing the experiment’s results? That’s where TensorBoard comes in.\n",
    "\n",
    "TensorBoard (www.tensorflow.org/tensorboard) is a browser-based application that\n",
    "you can run locally. It’s the best way to monitor everything that goes on inside your\n",
    "model during training. With TensorBoard, you can\n",
    "- Visually monitor metrics during training\n",
    "- Visualize your model architecture\n",
    "- Visualize histograms of activations and gradients\n",
    "- Explore embeddings in 3D\n",
    "\n",
    "If you’re monitoring more information than just the model’s final loss, you can\n",
    "develop a clearer vision of what the model does and doesn’t do, and you can make\n",
    "progress more quickly.\n",
    "\n",
    " The easiest way to use TensorBoard with a Keras model and the `fit()` method is to\n",
    "use the `keras.callbacks.TensorBoard` callback.\n",
    "\n",
    " In the simplest case, just specify where you want the callback to write logs, and\n",
    "you’re good to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7926057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2916 - accuracy: 0.9140 - val_loss: 0.1416 - val_accuracy: 0.9596\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1593 - accuracy: 0.9551 - val_loss: 0.1164 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1296 - accuracy: 0.9632 - val_loss: 0.1077 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1157 - accuracy: 0.9671 - val_loss: 0.1060 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1058 - accuracy: 0.9708 - val_loss: 0.0916 - val_accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.0951 - accuracy: 0.9757 - val_loss: 0.0922 - val_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.0912 - accuracy: 0.9757 - val_loss: 0.0920 - val_accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0861 - accuracy: 0.9776 - val_loss: 0.0912 - val_accuracy: 0.9784\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0782 - accuracy: 0.9782 - val_loss: 0.0838 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.0892 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a861f6620>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a699a40",
   "metadata": {},
   "source": [
    "Once the model starts running, it will write logs at the target location. If you are running your Python script on a local machine, you can then launch the local TensorBoard server using the following command (note that the `tensorboard` executable\n",
    "should be already available if you have installed TensorFlow via `pip`; if not, you can\n",
    "install TensorBoard manually via `pip install tensorboard`):\n",
    "\n",
    "`tensorboard --logdir /full_path_to_your_log_dir`\n",
    "\n",
    "You can then navigate to the URL that the command returns in order to access the\n",
    "TensorBoard interface.\n",
    "\n",
    " If you are running your script in a Colab notebook, you can run an embedded TensorBoard instance as part of your notebook, using the following commands:\n",
    " \n",
    "`%load_ext tensorboard`\n",
    "\n",
    "`%tensorboard --logdir /full_path_to_your_log_dir`\n",
    "\n",
    "In the TensorBoard interface, you will be able to monitor live graphs of your training\n",
    "and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8204e3",
   "metadata": {},
   "source": [
    "# 7.4 Writing your own training and evaluation loops\n",
    "\n",
    "The `fit()` workflow strikes a nice balance between ease of use and flexibility. It’s what\n",
    "you will use most of the time. However, it isn’t meant to support everything a deep\n",
    "learning researcher may want to do, even with custom metrics, custom losses, and custom callbacks.\n",
    "\n",
    " After all, the built-in `fit()` workflow is solely focused on supervised learning: a setup\n",
    "where there are known *targets* (also called *labels* or *annotations*) associated with your\n",
    "input data, and where you compute your loss as a function of these targets and the\n",
    "model’s predictions. However, not every form of machine learning falls into this\n",
    "category. There are other setups where no explicit targets are present, such as *generative learning* (which we will discuss in chapter 12), *self-supervised learning* (where targets\n",
    "are obtained from the inputs), and *reinforcement learning* (where learning is driven by\n",
    "occasional “rewards,” much like training a dog). Even if you’re doing regular supervised learning, as a researcher, you may want to add some novel bells and whistles that\n",
    "require low-level flexibility.\n",
    "\n",
    "Whenever you find yourself in a situation where the built-in `fit()` is not enough,\n",
    "you will need to write your own custom training logic. You already saw simple examples of low-level training loops in chapters 2 and 3. As a reminder, the contents of a\n",
    "typical training loop look like this:\n",
    "1. Run the forward pass (compute the model’s output) inside a gradient tape to\n",
    "obtain a loss value for the current batch of data.\n",
    "2. Retrieve the gradients of the loss with regard to the model’s weights.\n",
    "3. Update the model’s weights so as to lower the loss value on the current batch\n",
    "of data.\n",
    "\n",
    "These steps are repeated for as many batches as necessary. This is essentially what\n",
    "`fit()` does under the hood. In this section, you will learn to reimplement `fit()` from\n",
    "scratch, which will give you all the knowledge you need to write any training algorithm\n",
    "you may come up with.\n",
    " Let’s go over the details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46139ca0",
   "metadata": {},
   "source": [
    "## 7.4.1 Training vs. inference\n",
    "\n",
    "In the low-level training loop examples you’ve seen so far, step 1 (the forward pass)\n",
    "was done via `predictions = model(inputs)`, and step 2 (retrieving the gradients\n",
    "computed by the gradient tape) was done via `gradients = tape.gradient(loss,\n",
    "model.weights)`. In the general case, there are actually two subtleties you need to take\n",
    "into account.\n",
    "\n",
    "Some Keras layers, such as the `Dropout` layer, have different behaviors during training\n",
    "and during inference (when you use them to generate predictions). Such layers expose\n",
    "a `training` Boolean argument in their `call()` method. Calling `dropout(inputs,\n",
    "training=True)` will drop some activation entries, while calling `dropout(inputs,\n",
    "training=False)` does nothing. By extension, Functional and Sequential models also\n",
    "expose this training argument in their `call()` methods. Remember to pass `training\n",
    "=True` when you call a Keras model during the forward pass! Our forward pass thus\n",
    "becomes `predictions = model(inputs, training=True)`.\n",
    "\n",
    " In addition, note that when you retrieve the gradients of the weights of your\n",
    "model, you should not use `tape.gradients(loss, model.weights)`, but rather `tape\n",
    ".gradients(loss, model.trainable_weights)`. Indeed, layers and models own two\n",
    "kinds of weights:\n",
    "- *Trainable weights*—These are meant to be updated via backpropagation to minimize the loss of the model, such as the kernel and bias of a `Dense` layer.\n",
    "- *Non-trainable weights*—These are meant to be updated during the forward pass\n",
    "by the layers that own them. For instance, if you wanted a custom layer to keep\n",
    "a counter of how many batches it has processed so far, that information would\n",
    "be stored in a non-trainable weight, and at each batch, your layer would increment the counter by one.\n",
    "\n",
    "Among Keras built-in layers, the only layer that features non-trainable weights is the\n",
    "`BatchNormalization` layer, which we will discuss in chapter 9. The `BatchNormalization`\n",
    "layer needs non-trainable weights in order to track information about the mean and\n",
    "standard deviation of the data that passes through it, so as to perform an online\n",
    "approximation of *feature normalization* (a concept you learned about in chapter 6).\n",
    "\n",
    " Taking into account these two details, a supervised-learning training step ends up\n",
    "looking like this:\n",
    "\n",
    "```python\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradients(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(model.trainable_weights, gradients))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7948a",
   "metadata": {},
   "source": [
    "## 7.4.2 Low-level usage of metrics\n",
    "\n",
    "In a low-level training loop, you will probably want to leverage Keras metrics (whether\n",
    "custom ones or the built-in ones). You’ve already learned about the metrics API: simply call `update_state(y_true, y_pred)` for each batch of targets and predictions, and\n",
    "then use `result()` to query the current metric value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32578893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55317d93",
   "metadata": {},
   "source": [
    "You may also need to track the average of a scalar value, such as the model’s loss. You\n",
    "can do this via the `keras.metrics.Mean` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72cad425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d6367f",
   "metadata": {},
   "source": [
    "Remember to use `metric.reset_state()` when you want to reset the current results\n",
    "(at the start of a training epoch or at the start of evaluation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5330b444",
   "metadata": {},
   "source": [
    "## 7.4.3 A complete training and evaluation loop\n",
    "\n",
    "Let’s combine the forward pass, backward pass, and metrics tracking into a `fit()`-like\n",
    "training step function that takes a batch of data and targets and returns the logs that\n",
    "would get displayed by the `fit()` progress bar.\n",
    "\n",
    "### *Writing a step-by-step training loop: the training step function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba747b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "# Prepare the loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "# Prepare the optimizer\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "# Prepare a list of metrics to monitor.\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "# Prepare a Mean metric tracker to keep track of the loss average.\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    # Run the forward pass. Note that we pass training=True.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "        \n",
    "    # Run the backward pass. Note that we use the model.trainable_weights.\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    # Keep track of metrics.\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    \n",
    "    # Keep track of the loss average.\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    \n",
    "    # Return the current value of the metrics and the loss.\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b307bf",
   "metadata": {},
   "source": [
    "We will need to reset the state of our metrics at the start of each epoch and before running evaluation. Here's a utility function to do it.\n",
    "\n",
    "### *Writing a step-by-step training loop: resetting the metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed726c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dd51f",
   "metadata": {},
   "source": [
    "We can now lay out our complete training loop. Note that we use a `tf.data.Dataset` object to turn our NumPy data into an iterator that iterates over the data in batches of size 32.\n",
    "\n",
    "### *Writing a step-by-step training loop: the loop itself*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c6e4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9129\n",
      "...loss: 0.2919\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9533\n",
      "...loss: 0.1587\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9633\n",
      "...loss: 0.1291\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ae61e",
   "metadata": {},
   "source": [
    "And here’s the evaluation loop: a simple `for` loop that repeatedly calls a `test_step()`\n",
    "function, which processes a single batch of data. The `test_step()` function is just a subset of the logic of `train_step()`. It omits the code that deals with updating the weights\n",
    "of the model—that is to say, everything involving the `GradientTape` and the optimizer.\n",
    "\n",
    "### *Writing a step-by-step evaluation loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b446c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9689\n",
      "...val_loss: 0.1189\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    # Note that we pass training=False.\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "        \n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics() \n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a66ff",
   "metadata": {},
   "source": [
    "Congrats—you’ve just reimplemented `fit()` and `evaluate()`! Or almost: `fit()`\n",
    "and `evaluate()` support many more features, including large-scale distributed computation, which requires a bit more work. It also includes several key performance\n",
    "optimizations.\n",
    "\n",
    " Let’s take a look at one of these optimizations: TensorFlow function compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c5806",
   "metadata": {},
   "source": [
    "## 7.4.4 Make it fast with tf.function\n",
    "\n",
    "You may have noticed that your custom loops are running significantly slower than the\n",
    "built-in `fit()` and `evaluate()`, despite implementing essentially the same logic.\n",
    "That’s because, by default, TensorFlow code is executed line by line, *eagerly*, much like\n",
    "NumPy code or regular Python code. Eager execution makes it easier to debug your\n",
    "code, but it is far from optimal from a performance standpoint.\n",
    "\n",
    " It’s more performant to *compile* your TensorFlow code into a computation graph that\n",
    "can be globally optimized in a way that code interpreted line by line cannot. The syntax to do this is very simple: just add a `@tf.function` to any function you want to compile before executing.\n",
    "\n",
    "### *Adding a `@tf.function` decorator to our evaluation-step function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c6d547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9689\n",
      "...val_loss: 0.1189\n"
     ]
    }
   ],
   "source": [
    "@tf.function    # This is the only line that changed.\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "        \n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics() \n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab672b84",
   "metadata": {},
   "source": [
    "On the Colab CPU, we go from taking 1.80 s to run the evaluation loop to only 0.8 s.\n",
    "Much faster!\n",
    "\n",
    " Remember, while you are debugging your code, prefer running it eagerly, without\n",
    "any `@tf.function` decorator. It’s easier to track bugs this way. Once your code is working and you want to make it fast, add a `@tf.function` decorator to your training step\n",
    "and your evaluation step—or any other performance-critical function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5a45e",
   "metadata": {},
   "source": [
    "## 7.4.5 Leveraging `fit()` with a custom training loop\n",
    "\n",
    "In the previous sections, we were writing our own training loop entirely from scratch.\n",
    "Doing so provides you with the most flexibility, but you end up writing a lot of code\n",
    "while simultaneously missing out on many convenient features of `fit()`, such as callbacks or built-in support for distributed training.\n",
    "\n",
    "What if you need a custom training algorithm, but you still want to leverage the\n",
    "power of the built-in Keras training logic? There’s actually a middle ground between\n",
    "`fit()` and a training loop written from scratch: you can provide a custom training\n",
    "step function and let the framework do the rest.\n",
    "\n",
    " You can do this by overriding the `train_step()` method of the Model class. This is\n",
    "the function that is called by `fit(`) for every batch of data. You will then be able to call\n",
    "`fit()` as usual, and it will be running your own learning algorithm under the hood.\n",
    "\n",
    " Here’s a simple example:\n",
    "- We create a new class that subclasses `keras.Model`.\n",
    "- We override the method `train_step(self, data)`. Its contents are nearly identical to what we used in the previous section. It returns a dictionary mapping\n",
    "metric names (including the loss) to their current values.\n",
    "- We implement a `metrics` property that tracks the model’s `Metric` instances.\n",
    "This enables the model to automatically call `reset_state()` on the model’s\n",
    "metrics at the start of each epoch and at the start of a call to `evaluate()`, so you\n",
    "don’t have to do it by hand.\n",
    "\n",
    "### *Implementing a custom training step to use with `fit()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe75a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "# This metric object will be used to track the average of per-batch losses during training and evaluation.\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    # Overide the train_step method.\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # We use self(inputs, training=True) instead of model(inputs, training=True), since our model is the class itself.\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        \n",
    "        # Update the loss tracker metric that tracks the average of the loss.\n",
    "        loss_tracker.update_state(loss)\n",
    "        # Return the average loss so far by querying the loss tracker metric.\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d57fc",
   "metadata": {},
   "source": [
    "We can now instantiate our custom model, compile it (we only pass the optimizer, since\n",
    "the loss is already defined outside of the model), and train it using `fit()` as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337d41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2959\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1587\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a80524100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f37a0",
   "metadata": {},
   "source": [
    "There are a couple of points to note:\n",
    "- This pattern does not prevent you from building models with the Functional\n",
    "API. You can do this whether you’re building Sequential models, Functional\n",
    "API models, or subclassed models.\n",
    "- You don’t need to use a `@tf.function` decorator when you override `train_step`—the framework does it for you.\n",
    "\n",
    "Now, what about metrics, and what about configuring the loss via `compile()`? After\n",
    "you’ve called `compile()`, you get access to the following:\n",
    "- `self.compiled_loss`—The loss function you passed to `compile()`.\n",
    "- `self.compiled_metrics`—A wrapper for the list of metrics you passed, which\n",
    "allows you to call `self.compiled_metrics.update_state()` to update all of\n",
    "your metrics at once.\n",
    "- `self.metrics`—The actual list of metrics you passed to `compile()`. Note that it\n",
    "also includes a metric that tracks the loss, similar to what we did manually with\n",
    "our `loss_tracking_metric` earlier.\n",
    "\n",
    "We can thus write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7977a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            # Compute the loss via self.compiled_loss.\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        \n",
    "        # Update the model’s metrics via self.compiled_metrics.\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        \n",
    "        # Return a dict mapping metric names to their current value.\n",
    "        return {m.name: m.result() for m in self.metrics} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25adf137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.9121\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1297 - sparse_categorical_accuracy: 0.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a8715db10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0face",
   "metadata": {},
   "source": [
    "That was a lot of information, but you now know enough to use Keras to do almost\n",
    "anything. \n",
    "\n",
    "## *Summary*\n",
    "\n",
    "- Keras offers a spectrum of different workflows, based on the principle of *progressive disclosure of complexity*. They all smoothly inter-operate together.\n",
    "- You can build models via the `Sequential` class, via the Functional API, or by subclassing the `Model` class. Most of the time, you’ll be using the Functional API.\n",
    "- The simplest way to train and evaluate a model is via the default `fit()` and\n",
    "`evaluate()` methods.\n",
    "- Keras callbacks provide a simple way to monitor models during your call to\n",
    "`fit()` and automatically take action based on the state of the model.\n",
    "- You can also fully take control of what `fit()` does by overriding the `train_step()` method.\n",
    "- Beyond `fit()`, you can also write your own training loops entirely from scratch.\n",
    "This is useful for researchers implementing brand-new training algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62171f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
